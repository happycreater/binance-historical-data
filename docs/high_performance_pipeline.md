# 高性能、可扩展的数据下载与清洗方案

本文档给出一套面向 Binance Historical Data 的高性能、可扩展下载与清洗方案，设计参考现有的 `download.py` 与 `clean.py` 的核心思路（目录枚举、并发下载、逐文件清洗、增量处理），并补足可扩展性、容错与可观测性能力。

## 设计目标

- **高吞吐**：最大化带宽与 CPU 利用率，避免单点串行瓶颈。
- **可扩展**：易于横向扩展到多机器、多进程或容器编排环境。
- **可恢复**：支持断点续传、失败重试、幂等写入。
- **可观测**：暴露完整的状态、指标与日志，便于排错与优化。
- **数据一致性**：保证清洗后的输出可追溯、可重复、可验证。

## 总体架构

```
┌────────────────────────────┐
│        元数据控制层         │
│  任务清单/清单生成/状态表   │
└──────────────┬─────────────┘
               │
        (下载调度层)
               │
┌──────────────┴─────────────┐
│     下载执行层 (多线程)     │
│ 目录枚举 → 任务队列 → 下载 │
└──────────────┬─────────────┘
               │ (Raw 数据)
               ▼
┌────────────────────────────┐
│       清洗执行层 (并行)      │
│ 读取 → 解析 → 修正 → 输出   │
└──────────────┬─────────────┘
               │ (Parquet)
               ▼
┌────────────────────────────┐
│      统计与质量校验层       │
│ 统计汇总/校验/抽样复核等    │
└────────────────────────────┘
```

## 下载方案（参考 `download.py` 思路增强）

### 1. 任务枚举与清单

- **目录枚举**：沿用 `list_prefix` 的方式，从 S3-like 列表获取目录与文件信息，构建“zip 文件清单”。
- **任务清单持久化**：新增 `manifest` 文件（例如 `manifests/download_{date}.jsonl`），记录：
  - `symbol`、`pattern`、`url`、`etag/size`（可从响应头获取）、`status`、`last_error`。
- **增量能力**：每次扫描后对比 `manifest`，只下载新增或未完成的记录。

### 2. 调度与并发

- **生产者-消费者模型**：延续现有 `Queue` + 多线程消费者模型，生产者负责目录枚举，消费者负责下载。
- **可配置并发**：将 `download_workers`、`list_workers` 变为配置项，支持环境变量或配置文件。
- **速率限制/重试**：为下载加入指数退避重试、限速配置（必要时避免被服务器限制）。

### 3. 存储与断点续传

- **幂等写入**：下载前检查目标文件是否存在 + 校验 `etag/size` 是否匹配。
- **临时文件策略**：先下载至 `.partial`，完成后原子 `rename`。
- **文件层级结构**：保持 `data.binance.vision/<path>` 的分层，便于后续清洗快速定位。

### 4. 日志与监控

- **统一结构化日志**：延续当前 `download.log`，建议改为 JSON 日志以便采集与分析。
- **指标输出**：成功/失败/跳过/耗时/下载速率等指标打点。

## 清洗方案（参考 `clean.py` 思路增强）

### 1. 增量处理

- **处理状态记录**：保留现有 `processed.txt` 思路，但推荐升级为 `manifest` 或 `sqlite` 状态表，避免重复处理。
- **幂等输出**：清洗后输出 Parquet 时，通过分区和去重保证重复执行不产生差异。

### 2. 批处理与并行化

- **批量读取**：逐 zip 读入即可，但可将多个 zip 批量拼接后批量写入（减少 parquet 写次数）。
- **并行清洗**：按 `symbol` 分片，将清洗任务分发到多进程或分布式环境。

### 3. 数据标准化与修复

- **时间戳修复**：复用当前微秒级时间戳修正逻辑，但在清洗前统一校验范围。
- **Schema 管理**：显式定义字段类型与顺序，避免后续合并出现类型漂移。

### 4. 存储格式与分区

- **Parquet 分区**：在 `pattern/symbol/date` 等粒度上分区，提高查询效率。
- **统计信息**：清洗后生成 `stats.json`（行数、日期范围、缺失率等）。

## 可扩展性建议

### 1. 扩展到多节点

- 将 `manifest` 和状态表放入共享存储或数据库（Postgres、SQLite + NFS）。
- 下载与清洗节点通过统一任务队列协调（例如 Redis / RabbitMQ）。

### 2. 任务编排

- 使用 Airflow/Prefect 等编排工具实现“日常增量下载 → 清洗 → 校验 → 入库”全流程。

### 3. 语言与性能优化

- **Rust 优先**：使用 Rust 实现核心下载与清洗逻辑，以减少运行时开销并提升并发吞吐。
- **性能收益优先级**：优先优化 CPU 密集型环节（解压、解析、类型转换、去重、排序），再评估网络 I/O 的并发策略。

### 4. 异常处理策略

- 对单个 zip 的错误记录并跳过，不阻断全局任务。
- 对重复失败任务设定最大重试次数，超过阈值进入异常队列。

## 推荐模块拆分

```
project/
  download/
    indexer.py      # 目录枚举与清单生成
    scheduler.py    # 并发调度与任务分发
    downloader.py   # 下载执行
    manifest.py     # 下载状态管理
  clean/
    reader.py       # zip/CSV 读取
    transform.py    # 清洗与修复
    writer.py       # parquet 输出
    manifest.py     # 清洗状态管理
  common/
    logging.py      # 日志
    config.py       # 配置
```

## 与现有脚本的衔接方式

- 现有流程已在 Rust 中实现，可通过 Rust CLI 直接完成下载与清洗。
- 保留当前路径结构与 `pattern` 的使用方式，保证兼容原有目录结构。

---

通过上述方案，可以在保留现有代码思路（目录枚举、多线程下载、增量清洗）的前提下，显著提升吞吐、稳定性与可扩展性，适配大规模历史数据的持续下载与加工需求。
